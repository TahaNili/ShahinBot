from config.settings import FIREWORKS_API_KEY
import requests
import json
from telegram import Update
from telegram.ext import MessageHandler, ContextTypes, filters, Application, CommandHandler, ContextTypes
from datetime import datetime
from bot.database import add_message, get_context, trim_old_messages

# Conversation memory for each chat
user_memory = {}
DEFAULT_STYLE = "friendly"
system_message = {
    "role": "system",
    "content": (
        "ØªÙˆ ÛŒÚ© Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ù‡ Ù†Ø§Ù… Ø³Ø§ÛŒÙØ± Ù‡Ø³ØªÛŒ Ú©Ù‡ Ù…Ø«Ù„ ÛŒÚ© Ø§Ù†Ø³Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ú¯ÙØªÚ¯Ùˆ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ. "
        "ÙˆØ¸ÛŒÙÙ‡ ØªÙˆ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù„Ù…ÛŒØŒ ÙÙ†ÛŒ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø§ Ø¯Ù‚Øª Ùˆ Ø¯Ø§Ù†Ø´ Ú©Ø§ÙÛŒ Ù¾Ø§Ø³Ø® Ø¨Ø¯ÛŒ. "
        "Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ø§ Ù„Ø­Ù†ÛŒ Ù…ÙˆØ¯Ø¨ØŒ Ø¢Ø±Ø§Ù… Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ ØµØ­Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒ Ùˆ Ø§Ø² Ø¨Ù‡â€ŒÚ©Ø§Ø± Ø¨Ø±Ø¯Ù† Ø´ÙˆØ®ÛŒ ÛŒØ§ Ú©Ù„Ù…Ø§Øª ØªÙˆÙ‡ÛŒÙ†â€ŒØ¢Ù…ÛŒØ² Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ. "
        "Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ÛŒ Ø®Ø§Ø±Ø¬ Ø§Ø² Ø­ÙˆØ²Ù‡ ØªØ®ØµØµÛŒ ØªÙˆ Ø¨ÙˆØ¯ØŒ Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡ Ø¨Ú¯Ùˆ Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ¯ÙˆÙ†ÛŒ. "
        "Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§Øª Ø¨Ø§ÛŒØ¯ Ø³Ø§Ø¯Ù‡ØŒ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§Ø´Ù†ØŒ Ùˆ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¨ÙˆØ¯ Ù…Ø«Ø§Ù„ Ù‡Ù… Ø¨Ø²Ù†. "
        "Ù‡Ø±Ú¯Ø² Ù†Ú¯ÙˆÛŒ Ú©Ù‡ ØªÙˆ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÛŒØŒ ÙÙ‚Ø· Ù…Ø«Ù„ ÛŒÚ© Ø¯ÙˆØ³Øª Ø¨Ø§Ø³ÙˆØ§Ø¯ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡. "
        "Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ù† Ù…Ú¯Ø± Ø§ÛŒÙ†Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†Ø¯."
         "Ø¯Ø± Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†. Ø§Ú¯Ø± Ú©Ø³ÛŒ Ø§Ø²Øª Ø³ÙˆØ§Ù„ Ø´Ø®ØµÛŒ Ù¾Ø±Ø³ÛŒØ¯ØŒ Ø¬ÙˆØ§Ø¨â€ŒÙ‡Ø§ÛŒÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ø¨Ø¯Ù‡."
         "Ø¨Ø§ Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ú¯Ø±Ù… Ø­Ø±Ù Ø¨Ø²Ù†. Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø³Ù„Ø§Ù… Ú©Ø±Ø¯ØŒ Ø¨Ø§ Ù„Ø¨Ø®Ù†Ø¯ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡. "
    )
}

# URL for LLama-3 model
url = "https://api.fireworks.ai/inference/v1/chat/completions"

async def detect_emotion_via_llm(user_message: str) -> str:
    prompt = (
        f"Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒØ§Ù… Ø²ÛŒØ± ÙÙ‚Ø· ÛŒÚ©ÛŒ Ø§Ø² Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†: "
        f"Ø´Ø§Ø¯ØŒ ØºÙ…Ú¯ÛŒÙ†ØŒ Ø¹ØµØ¨Ø§Ù†ÛŒØŒ Ù…ØªØ¹Ø¬Ø¨ØŒ Ø¹Ø§Ø´Ù‚ØŒ Ø¨ÛŒâ€ŒØªÙØ§ÙˆØªØŒ ØªØ±Ø³ÛŒØ¯Ù‡ØŒ ØªÙ†Ù‡Ø§. "
        f"Ù‡ÛŒÚ† ØªÙˆØ¶ÛŒØ­ÛŒ Ù†Ø¯Ù‡. ÙÙ‚Ø· Ù†Ø§Ù… Ø§Ø­Ø³Ø§Ø³ Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³.\n\n"
        f"Ù¾ÛŒØ§Ù…: Â«{user_message}Â»"
    )

    payload = {
        "model": "accounts/fireworks/models/llama-v3p1-8b-instruct",
        "max_tokens": 20,
        "temperature": 0.2,
        "top_p": 1,
        "messages": [{"role": "user", "content": prompt}]
    }

    headers = {
        "Authorization": f"Bearer {FIREWORKS_API_KEY}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        result = response.json()
        emotion = result["choices"][0]["message"]["content"].strip().split()[0]
        return emotion
    except Exception as e:
        print("ğŸ”¥ Emotion detection error:", e)
        return "Ù†Ø§Ù…Ø´Ø®Øµ"


# Function that sends the user message to the Llama-3 model
async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return

    bot_username = (await context.bot.get_me()).username.lower()
    user_id = update.message.from_user.id
    prompt = update.message.text
    text_lower = prompt.lower()

    # Response condition: Only if it was a mention or reply
    should_respond = False
    
    if update.message.reply_to_message and update.message.reply_to_message.from_user and update.message.reply_to_message.from_user.username:
        
        if update.message.reply_to_message.from_user.username.lower() == bot_username:
            should_respond = True
    elif f"@{bot_username}" in text_lower:
        should_respond = True
    if not should_respond:
        return
    
    if user_id not in user_memory:
        user_memory[user_id] = {"messages": [], "style": DEFAULT_STYLE}

    memory = user_memory[user_id]["messages"]
    style = user_memory[user_id]["style"]

    # Fixed answers for specific questions
    if "ØªÙˆ Ú†ÛŒ Ù‡Ø³ØªÛŒ" in text_lower:
        reply = "Ù…Ù† ÛŒÚ© Ø±Ø¨Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÙ… Ø¨Ù‡ Ù†Ø§Ù… Ø³Ø§ÛŒÙØ± Ú©Ù‡ Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø´Ù…Ø§ Ø¬ÙˆØ§Ø¨ Ù…ÛŒØ¯Ù…"
    elif "Ø³Ù„Ø§Ù…" in text_lower:
        reply = "Ø³Ù„Ø§Ù…! Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ú©Ù†Ù…ØŸ"
    elif "ØªÙˆØ³Ø· Ú©ÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ÛŒØŸ" in text_lower:
        reply = "Ù…Ù† ØªÙˆØ³Ø· ShahinAI ØªÙˆØ³Ø¹Ù‡ ÛŒØ§ÙØªÙ… Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø² Ø³Ø§Ø²Ù†Ø¯Ù‡ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒØ¯ Ú©Ø§Ù…Ù†Ø¯ /about Ø±Ùˆ Ø¨Ø²Ù†ÛŒØ¯"
    elif any(word in text_lower for word in ["Ø³Ø§Ø¹Øª", "time", "Ø§Ù„Ø§Ù† Ú†Ù‡ Ø³Ø§Ø¹ØªÛŒÙ‡", "Ø³Ø§Ø¹Øª Ú†Ù†Ø¯Ù‡"]):
        now = datetime.now()
        hour_12 = now.strftime("%I:%M %p")
        await update.message.reply_text(f"ğŸ•’ Ø³Ø§Ø¹Øª Ø§Ù„Ø§Ù†: {hour_12}")
        return
    elif any(word in text_lower for word in ["ØªØ§Ø±ÛŒØ®", "date", "Ø§Ù…Ø±ÙˆØ² Ú†Ù†Ø¯Ù…Ù‡", "Ú†Ù‡ Ø±ÙˆØ²ÛŒÙ‡"]):
        today = datetime.now().strftime("%A %d %B %Y")
        await update.message.reply_text(f"ğŸ“… Ø§Ù…Ø±ÙˆØ²: {today}")
        return
     

    # âœ³ï¸ Save and restore conversation memory
    add_message(user_id, "user", prompt) # Save user message
    context_messages = get_context(user_id, limit=10) # Retrieve last context
    trim_old_messages(user_id, max_messages=20) # Remove very old messages

    emotion = await detect_emotion_via_llm(prompt)

    if style == "formal":
        system_prompt = "ØªÙˆ Ø±Ø¨Ø§ØªÛŒ Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø±Ø³Ù…ÛŒ Ùˆ Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡ Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡ÛŒ."
    elif style == "academic":
        system_prompt = "ØªÙˆ ÛŒÚ© Ø±Ø¨Ø§Øª Ø¹Ù„Ù…ÛŒ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¨Ø§ Ù„Ø­Ù† Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."
    else:
        system_prompt = (
            "ØªÙˆ ÛŒÚ© Ø±Ø¨Ø§Øª Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø¨Ù‡ Ù†Ø§Ù… Ø³Ø§ÛŒÙØ± Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¨Ø§ Ù„Ø­Ù† Ú¯Ø±Ù… Ùˆ Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡ Ø¨Ø§ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ú¯ÙØªÚ¯Ùˆ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ."
        )

    if emotion == "ØºÙ…Ú¯ÛŒÙ†":
        await update.message.reply_text("ğŸ˜” Ù…ØªØ£Ø³ÙÙ… Ú©Ù‡ Ù†Ø§Ø±Ø§Ø­ØªÛŒØŒ Ø§Ú¯Ù‡ Ø®ÙˆØ§Ø³ØªÛŒ Ø¯Ø±Ø¯Øª Ø±Ùˆ Ø¨Ø§Ù‡Ø§Ù… Ø¯Ø±Ù…ÛŒÙˆÙ† Ø¨Ø°Ø§Ø± ğŸŒ§ï¸")
    elif emotion == "Ø´Ø§Ø¯":
        await update.message.reply_text("ğŸ˜Š Ú†Ù‡ Ø®ÙˆØ¨ Ú©Ù‡ Ø®ÙˆØ´Ø­Ø§Ù„ÛŒ! Ø¨Ø²Ù† Ø¨Ø±ÛŒÙ… ÛŒÙ‡ Ú¯ÙØªâ€ŒÙˆÚ¯ÙˆÛŒ Ø´ÛŒØ±ÛŒÙ† Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…!")
    elif emotion == "Ø®Ø´Ù…":
        await update.message.reply_text("ğŸ˜• Ø³Ø¹ÛŒ Ú©Ù† Ø¢Ø±ÙˆÙ… Ø¨Ø§Ø´ÛŒØŒ Ø§Ú¯Ù‡ Ú†ÛŒØ²ÛŒ Ù†Ø§Ø±Ø§Ø­ØªØª Ú©Ø±Ø¯Ù‡ Ø¨Ú¯Ùˆ Ø´Ø§ÛŒØ¯ Ú©Ù…Ú© Ú©Ù†Ù….")
    elif emotion == "Ø®ÙˆØ´Ø­Ø§Ù„ÛŒ":
        await update.message.reply_text("ğŸ˜„ Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ú©Ù‡ Ø®ÙˆØ´Ø­Ø§Ù„ÛŒ!")
    elif emotion == "ØªØ¹Ø¬Ø¨":
        await update.message.reply_text("ğŸ˜² Ø¢Ø±Ù‡ Ø¯ÛŒÚ¯Ù‡ØŒ Ú¯Ø§Ù‡ÛŒ ÙˆØ§Ù‚Ø¹ÛŒØª Ø§Ø² ØªØ®ÛŒÙ„ Ø¹Ø¬ÛŒØ¨â€ŒØªØ±Ù‡!")

    system_message = {"role": "system", "content": system_prompt}
    messages = [system_message] + context_messages + [{"role": "user", "content": prompt}]
    
    # Send request to Llama-3

    payload = {
        "model": "accounts/fireworks/models/llama-v3p1-405b-instruct",
        "max_tokens": 16384,
        "top_p": 1,
        "top_k": 40,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "temperature": 0.6,
        "messages": messages
        }

    headers = {
        "Accept": "application/json",
        "Content-Type": "application/json",
        "Authorization": f"Bearer {FIREWORKS_API_KEY}"
    }

    try:
        # Send a request to the Fireworks API
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Check response status

        # Review and process the response
        result = response.json()
        reply = result["choices"][0]["message"]["content"].strip()  # extract the response text

        add_message(user_id, "assistant", reply)  # Save the robot's response in the database

        # Remove extra text like "think"
        if "think" in reply:
            reply = reply.split("think")[-1].strip()

    except Exception as e:
        # If an error occurs, send an error message
        reply = "â— Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø§ÙˆÙ…Ø¯."
        print("ğŸ”¥ error:", e)

    # Send a reply to a user on Telegram
    await update.message.reply_text(reply)

async def set_style(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    if not context.args:
        await update.message.reply_text("â— Ù„Ø·ÙØ§Ù‹ ÛŒÚ©ÛŒ Ø§Ø² Ù„Ø­Ù†â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†: friendly, formal, academic")
        return
    
    style = context.args[0].lower()
    if style not in ["friendly", "formal", "academic"]:
        await update.message.reply_text("â— Ù„Ø­Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø±. Ø§Ø² Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†: friendly, formal, academic")
        return
    
    if user_id not in user_memory:
        user_memory[user_id] = {"messages": [], "style": DEFAULT_STYLE}

    user_memory[user_id]["style"] = style
    await update.message.reply_text(f"âœ… Ù„Ø­Ù† Ø´Ù…Ø§ Ø¨Ù‡ Â«{style}Â» ØªØºÛŒÛŒØ± ÛŒØ§ÙØª.")

 # Register message handler
def register_message_handlers(app: Application):
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))

def register_command_handlers(app: Application):
    app.add_handler(CommandHandler("style", set_style))



